#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 3cm
\topmargin 4cm
\rightmargin 3cm
\bottommargin 4cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Interim Report
\end_layout

\begin_layout Author
Luke Tomlin
\end_layout

\begin_layout Date
29/12/2012
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
The projects main objectives can be summarised by one sentence - to mimic
 how a person would learn to fly and operate a small remote control helicopter
 in an indoor environment.
 This objective is an interesting one, as it can be split into key areas
 of focus, each providing an engineering challenge, and then they all need
 to be combined to create the finished product.
 The problem is best described by the limiting factors - we have a room
 indoors, a small remote-controlled helicopter, a computer and a simple
 camera source capable of estimating depth to some degree of accuracy.
 With these boundaries, the final aim is to have the computer learn to fly
 the helicopter, and given goals from a human, enact them correctly.
 The difficulties are in the details - how exactly does one learn to fly
 a helicopter? How will we reliably get positional information for the helicopte
r in the room? These are just a few of the potential problems.
\end_layout

\begin_layout Paragraph
Deconstruction
\end_layout

\begin_layout Standard
The first step is to try and separate the individual programming problems
 into a way that is easily reasoned about.
 Once they have been divided, research can be done on the specific problems,
 and tools can be created to start tackling the problems at hand.
 For instance, the computer vision problem is entirely different from that
 of the machine learning - the machine operates under the assumption that
 the positional information is mostly accurate, and it is up to the computer
 vision module to provide these mostly accurate readings.
\end_layout

\begin_layout Paragraph
Mimicry
\end_layout

\begin_layout Standard
I decided to tackle this problem by thinking about how a human would go
 about it, reducing it to the key problems and then thinking about how a
 machine could go about tackling them.
 The final project will be split into modules, each providing a different
 role.
\end_layout

\begin_layout Paragraph
Complexity
\end_layout

\begin_layout Standard
The easiest place to see the complexity in this project is by looking at
 the computer vision aspect.
 Initially I will try to deal with the simplest case - that of a purely
 virtualised environment with completely controlled variables - no computer
 vision required.
 Then, for the first step, I will try to work in 1 dimension only, that
 is up and down.
 This restricts the vision to 1 dimension also, tracking the movement of
 a blob up and down.
 Expanding this to 2 dimensions should not be as much of a problem from
 the computer vision perspective, but requires increased complexity of the
 AI itself - it needs to know 
\begin_inset Formula $how$
\end_inset

 a helicopter moves forward and backwards, using the main propellor for
 upwards and forwards thrust.
 Expanding to 3 dimensions provides even more challenges - from navigating
 a 3 dimension environment (obtaining depth information and object awareness)
 to reasoning about the movements of a helicopter in a 3D environment.
 
\end_layout

\begin_layout Paragraph
Computer Vision
\end_layout

\begin_layout Standard
As discussed above, there are a multitude of tasks that need to be performed
 from a vision perspective before the overall aims can be realised.
 I aim to start from as simplified as possible, simply tracking an object
 on a 2D white background, and then from this gradually iterate the vision
 module, adding extra functionality and dimensions.
 Each iteration will present its own challenges, from getting depth information
 to tracking orientation of the helicopter.
\end_layout

\begin_layout Paragraph
Machine Learning
\end_layout

\begin_layout Standard
The AI that flies the helicopter is wholly separate from the vision, and
 instead is supposed to recreate the learning aspects of the abstract idea
 of a helicopter.
 Its key requirement is to know exactly how to fly the helicopter, given
 information about the current whereabouts, and know how to act upon the
 orders that it is given.
 
\end_layout

\begin_layout Paragraph
Technology
\end_layout

\begin_layout Standard
To aid the realisation of the aims, I plan to use some 
\begin_inset Quotes eld
\end_inset

pre-made
\begin_inset Quotes erd
\end_inset

 technology.
 This will allow me to focus on the project as the whole.
 
\end_layout

\begin_layout Subparagraph*
Kinect
\end_layout

\begin_layout Standard
For the computer vision, I will use a Kinect sensor device, created by Microsoft
, which provides me with both an RGB camera and a method for calculating
 depth of the image.
 Additionally, there are several freely available open-source software kits
 for interacting with the Kinect on any platform.
 This should make the computer vision aspect simpler, as I will be able
 to use the depth map that the kinect generates to augment any results I
 get from the single camera source.
 It is also a very popular device for performing computer vision with -
 this means that there will most likely be many other examples of it being
 used for tasks similar to mine.
 
\end_layout

\begin_layout Subparagraph*
OpenCV
\end_layout

\begin_layout Standard
OpenCV (Open Source Computer Vision Library) is a library of programming
 functions that will let me perform image analysis from the Kinect.
 It is free to use, and has many different implementations in different
 programming languages.
\end_layout

\begin_layout Subparagraph*
Arduino
\end_layout

\begin_layout Standard
Arduino is an open-source microcontroller, which lets the user work with
 a simple programming language to control how the circuit works.
 It also comes with a Processing-based IDE for programming in, that handles
 a lot of the communications between the board and the computer.
 Additionally, the board itself is reasonably cheap to purchase and highly
 re-usable.
\end_layout

\begin_layout Subparagraph*
Syma Remote Control Helicopter
\end_layout

\begin_layout Standard
The Syma Remote Control Helicopter is a small indoors helicopter, that is
 controlled by an IR source sent from a remote control.
 It is modelled to be easy to fly indoors, and to remain stable even in
 in-experienced hands.
 It does this my not having a traditional tail rotor - instead, it has an
 internal gyroscope that keeps it level, and rotation is accomplished by
 speeding up and slowing down the main rotor.
 The tail rotor is instead positioned facing upwards, and provides a tilting
 force to the tail, letting the helicopter fly forwards and backwards.
 This makes the helicopter extremely stable, at the sacrifice of not being
 able to tilt left or right.
 Ultimately, this only serves to make it easier to fly.
 The details on the communication protocols of the helicopter are not freely
 available, but some third party sources have done their own analysis of
 the signals (using oscilloscopes for example), and this should prove to
 be sufficient.
\end_layout

\begin_layout Section
Background
\end_layout

\begin_layout Standard
The whole basis from this project is from a suggestion by Google engineer
 Johnny Chung Lee, from his blog post 
\begin_inset Quotes eld
\end_inset

Computer Controlling a Syma Helicopter
\begin_inset Quotes erd
\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Syma"

\end_inset

.
 In his post, he talks about possible methods for setting up the control
 of a remote helicopter, as far as controlling it manually from a computer.
 He then conjectures the possibility of using a camera or similar to control
 the helicopter, and getting it to hover.
 He leaves the detail of this up to the user, however!
\end_layout

\begin_layout Standard
Armed with this inspiration for a starting point, I took to reading some
 detail for how I would set the foundations of the project up.
 This included browsing some other pages on using Arduino
\begin_inset CommandInset citation
LatexCommand cite
key "Arduino,Syma2"

\end_inset

, IR control of the helicopter
\begin_inset CommandInset citation
LatexCommand cite
key "IR"

\end_inset

 and circuit plans
\begin_inset CommandInset citation
LatexCommand cite
key "Syma2"

\end_inset

.
 There was a lot of trial and error involved with the building of the circuit,
 as I had done any electrical engineering for many years! Initially I built
 a simple LED circuit to get a feel for how the Arduino itself worked, and
 then once I was confident with that I built the main IR circuit.
 This proved to work well enough, however there were some teething problems
 - the helicopter would jutter and work sporadically.
 The problem because better and worse as I changed the timing values for
 the IR signals, so it was evident that it was a problem with the signal.
 After doing some further reading on precise timing using the Arduino
\begin_inset CommandInset citation
LatexCommand cite
key "Arduino port"

\end_inset

, and some trial and error, I found the value range that seemed to work
 best, or at least well enough for me.
 
\end_layout

\begin_layout Standard
I took a small amount of time to consider the feasibility of Arduino for
 the task at hand - for instance, would it be possible to do the whole project
 on a Raspberry Pi (http://www.raspberrypi.org/)? Or will the Arduino be too
 restrictive for my requirements? I decided that as the main part of this
 project was based upon the restrictions of input, and execution, not processing
 power, it would be needlessly limiting to use a Raspberry Pi or other similar
 device instead of a computer.
 Additionally, a computer would have a much wider range of tools available
 to it, making the project conceptually simpler.
 The Arduino could be used as a simple intermediate device, that takes the
 commands from the computer and sends them on to the helicopter, which does
 not require much computational power.
\end_layout

\begin_layout Standard
With my initial goals in mind, I started to build the foundation for the
 project using the programming language Haskell.
 I decided to use Haskell because I knew that it has an extensive programming
 library available to it, has bindings to the OpenCV library, and I had
 previously done a group project to create an AI framework in Haskell, which
 seemed appropriate given the topic of this project.
 This foundation involved making the various interfaces for the different
 parts of the project (modules, classes etc.), and deciding what responsibilities
 would be where.
 
\end_layout

\begin_layout Subsection
Prior work
\end_layout

\begin_layout Standard
Whilst researching methods and learning materials for the project, I came
 across examples of similar work that other people have performed, namely
 using quadcopters.
 Quadcopters (also known as quadrocopters) are small flying machines that
 have four individual propellers arranged in a square.
 Navigation is accomplished by powering the propellers at different speeds,
 causing the platform as a whole to tilt.
 Quadcopters are reknown for their stability and simple design.
\end_layout

\begin_layout Subsubsection
Quadrocopter experiments, Technical University Munich
\end_layout

\begin_layout Standard
Three students at the Technical University Munich wrote a paper titled 
\begin_inset Quotes eld
\end_inset

Camera-Based Navigation of a Low-Cost Quadrocopter
\begin_inset Quotes erd
\end_inset

, detailing 
\begin_inset Quotes eld
\end_inset

a system that enables a low-cost quadrocopter coupled with a ground-based
 laptop to naviage autonomously in previously unknown and GPS-denied environment
s
\begin_inset Quotes erd
\end_inset

.
 This project shares many similar points with mine - it is done using a
 low-cost flying device, without customised, high-precision location data
 sources, uses (amongst other things) a monocular vision device, and works
 indoors in previously unknown environments.
 However, it is also different in many ways, not just in the fact that it
 is using a quadcopter instead of a helicopter - it also has access to other
 on-board camera sources and flight information (it also has a 3-axis gyroscope
 and accelerometer and an ultrasound altimeter).
 Despite these differences, I should still be able to get some useful informatio
n from this project.
\end_layout

\begin_layout Paragraph*
Monocular SLAM
\end_layout

\begin_layout Paragraph*
Extended Kalman Filter
\end_layout

\begin_layout Subsection
Learning models
\end_layout

\begin_layout Standard
A key consideration I had to make at this point was what method I would
 use to 'learn' the correspondence between resultant acceleration and input
 power to the helicopter.
 The mapping between these two would be extremely important in flying the
 helicopter later, as I would want the helicopter to be able to make judgements
 on the appropriate input for a desired acceleration, and then to augment
 this mapping with observations.
 For the straight up/down case, where changing the input throttle results
 in a flat increase in propellor speed, and hence change in upwards velocity
 of the helicopter, I pulled out the key requirements:
\end_layout

\begin_layout Itemize
It needs to be able to return a mapping between acceleration and power.
 
\end_layout

\begin_layout Itemize
It needs to be able to update itself when receiving a new input power and
 the observed output acceleration.
\end_layout

\begin_layout Itemize
It needs to be able to create an initial model with very little input at
 all, that can rapidly re-evaluate itself using the above two methods.
\end_layout

\begin_layout Standard
Some initial considerations were using least squares and various similar
 deriviations, temporal difference learning, or a kalman filter of sorts.
 At first I implemented a basic least squares algorithm, as it appeared
 to be the simplest of the three and would be easy to implement.
 Additionally, by implementing it I might be able to see any problems that
 could emerge if I were to do any other methods in the future.
\end_layout

\begin_layout Subsubsection
Least Squares 
\end_layout

\begin_layout Standard
I performed some initial research on least squares algorithms, and how appropria
te they would be to the problem at hand.
 Initially, I was more interested in looking for an algorithm that would
 be iterative, and not require recomputation on the entire data set every
 time a new piece of data arrived.
 This was because I was afraid that the computations would quickly become
 slow as the measurements got larger and larger.
 Some sources discussed recursive versions of least squares estimation 
\begin_inset CommandInset citation
LatexCommand cite
key "Least squares + Recursive,Least squares wiki"

\end_inset

, but after spending some time looking at the algorithms and realising my
 own lack of knowledge on the subject of regression analysis, I decided
 to first implement the simple least squares algorithm and then possibly
 look at the recursive version later.
 Without too many problems I managed to implement the basic least squares
 algorithm into my program using a couple of different sources for inspiration
\begin_inset CommandInset citation
LatexCommand cite
key "Least squares wiki"

\end_inset

.
 To ensure that the calculations were as efficient as they could be, I made
 use of the Numeric.LinearAlgebra haskell package (http://hackage.haskell.org/packa
ges/archive/hmatrix/0.8.3.1/doc/html/Numeric-LinearAlgebra-Algorithms.html)
 which provides a bunch of data structures and functions for performing
 linear algebra.
 Doing some initial tests in ghci, this proved to be quite efficient, with
 satisfactory solve times for sample sets of sizes up to 1000, which, considerin
g a seemingly suitable sample time of 100ms, results in a respectable 100
 seconds of input data to base flying judgements on.
 
\end_layout

\begin_layout Standard
In addition to the normal least squares implementation, I was able to do
 some tests with a weighted least squares variant
\begin_inset CommandInset citation
LatexCommand cite
key "Least squares wiki"

\end_inset

.
 This involves giving each input/output measurement a weight, and the resulting
 map is skewed based on this weight.
 The benefit of this would be potentially letting me add 'ages' to the inputs,
 giving more recent and presumably thus more accurate depictions of the
 current state of the helicopter higher priority.
 
\end_layout

\begin_layout Standard
One of the other advantages of the least squares implementation was that
 it would let me easily change the model from linear to quadratic, depending
 on what the underlying system might represent.
 
\end_layout

\begin_layout Subsubsection
Temporal difference learning
\end_layout

\begin_layout Subsection
Vision
\end_layout

\begin_layout Standard
As has been mentioned earlier, I have decided to use a Kinect camera as
 my vision input source.
 The Kinect is not just an RGB camera - it is also a fairly accurate depth
 sensor, and this extra dimension of input could potentially make many of
 the problems that I am trying to solve easier.
 Upon receiving the Kinect from my supervisor, I set about getting it up
 and running with the Ubuntu operating system that I work on, searching
 for libraries and tools for it.
 In addition to this, it was important that I would be able to get the Kinect
 working in Haskell without too much problem, otherwise I would have to
 write a tool for this as well.
 Fortunately, after a little bit of looking around, I stumbled upon freenect
 (http://hackage.haskell.org/package/freenect), a Haskell interface to the
 Kinect device.
 However, the hackage version of freenect only has depth sensor support,
 but fortunately a kind fellow named Kevin Conley extended the library to
 include this 
\begin_inset CommandInset citation
LatexCommand cite
key "freenect,freenect paper"

\end_inset

.
 This meant that I could begin working on learning and using OpenCV directly
 without having to fuss with how I would incorporate the Kinect into Haskell.
\end_layout

\begin_layout Subsubsection
OpenCV
\end_layout

\begin_layout Standard
For my initial research on OpenCV, I began reading some tutorials and online
 documentation
\begin_inset CommandInset citation
LatexCommand cite
key "OpenCV book"

\end_inset

, as well as looking at existing examples in the Haskell wrapper for OpenCV
\begin_inset CommandInset citation
LatexCommand cite
key "OpenCV examples"

\end_inset

.
 I aimed to follow the general learning flow from the book (implemented
 in C++), but to do it myself in Haskell, thus hopefully learning both OpenCV
 and the wrapper itself.
 My first aim after doing some basic exercises was to get basic shape recognitio
n working on a plain white background (eg.
 my wall).
 
\end_layout

\begin_layout Standard
[Results]
\end_layout

\begin_layout Section
Project plan
\end_layout

\begin_layout Standard
The project as a whole can be split into multiple stages, and each of these
 stages is composed of discrete parts.
 
\end_layout

\begin_layout Subsection
Milestones
\end_layout

\begin_layout Standard
These are the key things that need to be done - these milestones define
 the project as a whole.
\end_layout

\begin_layout Subsubsection
Technology research and foundation implementations
\end_layout

\begin_layout Standard
Before I begin doing any programming, I have to research the technologies
 that I am going to use, and see how they will all fit together.
 This includes finding documentation for the technologies, learning to use
 them, and judging their usefulness.
 I can accomplish these by performing small modular experiments with each
 piece of technology.
 Additionally, there are several parts of the project that are essential
 and must be implemented as a 'foundation' before I can even begin any work
 at all!
\end_layout

\begin_layout Paragraph*
Back-engineering the RC protocol
\end_layout

\begin_layout Standard
To control the remote control helicopter from a computer, it was essential
 to be able to accurately replicate the signal that is sent from the normal
 stock controller.
 There were a variety of sources on the internet that had already done things
 similar to this before, so I was able to get a rough idea of where to start
 from there, and then performed my own experimentation to see what was best.
 In addition to just figuring out how the protocol worked, I had to think
 of a way to actually send the signal to the helicopter! I did some research
 online, and decided to use an Arduino board.
 After some fiddling around with the Arduino language, I was able to create
 a simple circuit that could send pulses to the helicopter.
 From here it was just playing around with different variations of the protocol
 to see which one worked best.
\end_layout

\begin_layout Paragraph*
Tool creation
\end_layout

\begin_layout Standard
At this point I had to create the basic tools with which I would create
 the finished product.
 These included the interface from the AI to the Arduino, a GUI so I could
 manually control the helicopter from the computer, and a simulation environment
 so I could play around with the AI in a controlled environment before trying
 it in the real thing.
 These tools would also partially define the project structure, as I would
 need to eventually get each of the tools working together.
\end_layout

\begin_layout Subsubsection
Monkey
\end_layout

\begin_layout Standard
I decided to name the AI a 'Monkey', as I figured that would fit in with
 the mimicry motto 
\begin_inset Quotes eld
\end_inset

monkey see, monkey do
\begin_inset Quotes erd
\end_inset

.
 The monkey had to be able to replicate how a human would learn to fly a
 helicopter.
 At the simplest level, the monkey operates under the knowledge of the current
 position of the helicopter in 3D space, and the time of that observation.
 The monkey does not worry exactly how this position is found, it just works
 on how to fly the helicopter from the information that it is receiving.
 This milestone is actually in several different parts - each one more complex
 than the last.
 
\end_layout

\begin_layout Subsubsection
Vision
\end_layout

\begin_layout Standard
The vision part is responsible for obtaining a reliable and quick value
 for the current position of the helicopter in 3D space, as well as (later
 on) providing other spacial information that might be relevant.
 I'll start simple, doing basic shape detection on a plain background in
 2D, and then later on try to expand this to 3D by getting depth information
 and try to get orientation information about the helicopter.
 It mostly goes hand in hand with the Monkey milestones, as each step in
 complexity in the monkey requires equivalent jumps in complexity from the
 vision system.
\end_layout

\begin_layout Subsection
Timetable
\end_layout

\begin_layout Standard
Here is a rough timetable for the project:
\end_layout

\begin_layout Description
Pre-January Have all foundation tech done - simple simulations, controls
 from computer, simple AI framework, GUI.
 Interim report.
\end_layout

\begin_layout Description
February Basic hover/landing working in simulation and on real-helicopter.
 Start improving computer vision techniques.
\end_layout

\begin_layout Subsubsection
What I've done so far
\end_layout

\begin_layout Standard
Up to the point of this report, I've so far managed to write most of the
 tools, design the basic framework for the AI, and have started implementing
 the simple foundation of the computer vision.
 I can fly the helicopter manually using a computer, and I can also fly
 the virtual helicopter manually.
 Additionally, I have implemented some basic learning algorithms, and I
 am still testing these to see which ones are best.
 The main requirements for me to reach my first major milestone at this
 stage are to get the basic computer vision working, tracking the helicopter
 in one dimension, and then to give this data to the Monkey and see how
 it works.
 Hopefully at that point it should be a simple deal of tweaking some of
 the behaviours of the monkey to get the helicopter hovering in one place.
\end_layout

\begin_layout Standard
Once this milestone is reached, I will spend a small amount of time cleaning
 up code and making sure that everything is stable for further progress,
 and then begin working on getting the Monkey working in two dimensions.
\end_layout

\begin_layout Subsection
Extensions
\end_layout

\begin_layout Standard
My provisional aim for this project is to be able to fly the helicopter
 in three dimensions, in a pre-planned trajectory.
\end_layout

\begin_layout Section
Evaluation plan
\end_layout

\begin_layout Subsubsection
Required functionality
\end_layout

\begin_layout Enumerate
Automated flight with no input other than camera.
\end_layout

\begin_layout Enumerate
Input of 'intentions', and automatic execution of them.
\end_layout

\begin_layout Enumerate
Movement in one, two and three dimensions.
\end_layout

\begin_layout Subsubsection
Quality of functionality
\end_layout

\begin_layout Standard
It should prove to be quite simple to ascertain the quality of the functionality
:
\end_layout

\begin_layout Description
Observation It will be fairly evident from how the helicopter flies according
 to the given instructions how well the project is performing.
 For instance, a steady, certain flight path would be good whereas a juddering
 path, or even crashing, would indicate bad performance!
\end_layout

\begin_layout Description
Execution The ability to execute more and more complicated intentions.
 Simply hovering in a given position should prove to be a (comparatively)
 simple feat, whereas flying from one position to another is more demanding.
 Extending this to customisable paths in three dimensional space would show
 that the underlying mechanisms are of high quality and performance.
\end_layout

\begin_layout Description
Extensibility If the system is set up well, it should be easy to extend
 it with new abilities and features, using the existing functionality.
\end_layout

\begin_layout Standard
These could be measured using the following demonstration, for example:
\end_layout

\begin_layout Enumerate
Demonstrate the ability to fly the helicopter from the computer manually.
 
\shape italic
Demonstrates the foundations of the project.
 
\end_layout

\begin_layout Enumerate
Demonstrate the ability to hover the helicopter in place, even when displaced.
 
\shape italic
Demonstrates the static control of the helicopter from a single camera source
 in multiple dimensions.
 
\end_layout

\begin_layout Enumerate
Demonstrate the ability to move in a predefined path.
 
\shape italic
Demonstrates advanced functionality.
 
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "Syma"

\end_inset

Lee, J.
 (2011) Procrastineering - Project blog for Johnny Chung Lee: Computer Controlli
ng a Syma Helicopter.
 [online] Available at: http://procrastineering.blogspot.co.uk/2011/11/computer-con
trolling-syma-helicopter.html [Accessed: 1 Jan 2013].
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "Syma2"

\end_inset

Avergottini.com (2011) Couch Sprout: Arduino helicopter infrared controller.
 [online] Available at: http://www.avergottini.com/2011/05/arduino-helicopter-infr
ared-controller.html [Accessed: 1 Jan 2013].
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "Arduino"

\end_inset

Arduino.cc (n.d.) Arduino - Guide.
 [online] Available at: http://arduino.cc/en/Guide/Guide [Accessed: 1 Jan
 2013].
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "IR"

\end_inset

Ladyada.net (2012) Sensor tutorials - IR remote receiver/decoder tutorial.
 [online] Available at: http://www.ladyada.net/learn/sensors/ir.html [Accessed:
 1 Jan 2013].
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "Arduino port"

\end_inset

Arduino.cc (n.d.) Arduino - PortManipulation.
 [online] Available at: http://www.arduino.cc/en/Reference/PortManipulation
 [Accessed: 1 Jan 2013].
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "freenect paper"

\end_inset

Conley, K.
 (2012) Adding Video Support to Christopher Done’s Haskell Kinect Library.
 [e-book] http://static.kevintechnology.com/docs/cis194.pdf.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "freenect"

\end_inset

kevincon (2012) freenect.
 [online] Available at: https://github.com/kevincon/freenect [Accessed: 4
 Jan 2013].
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "Least squares + Recursive"

\end_inset

Unknown.
 (2010) Recursive Least Squares Estimation.
 [e-book] Available through: http://www.cs.iastate.edu http://www.cs.iastate.edu/~cs57
7/handouts/recursive-least-squares.pdf.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "Recursive least squares"

\end_inset

Unknown.
 (n.d.) Lecture 10: Recursive Least Squares Estimation.
 [e-book] Available through: http://www.cs.tut.fi http://www.cs.tut.fi/~tabus/course/A
SP/LectureNew10.pdf.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "Least squares wiki"

\end_inset

En.wikipedia.org (2012) Least squares - Wikipedia, the free encyclopedia.
 [online] Available at: http://en.wikipedia.org/wiki/Least_squares [Accessed:
 4 Jan 2013].
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "OpenCV book"

\end_inset

BRADSKI, G.
 R., & KAEHLER, A.
 (2008).
 Learning OpenCV: computer vision with the OpenCV library.
 Sebastopol, CA, O'Reilly.
\end_layout

\begin_layout Bibliography
\begin_inset CommandInset bibitem
LatexCommand bibitem
key "OpenCV examples"

\end_inset

aleator (2012) CV.
 [online] Available at: https://github.com/aleator/CV/tree/master/examples
 [Accessed: 5 Jan 2013].
\end_layout

\end_body
\end_document
